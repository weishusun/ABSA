# scripts/web/export_product_json.py
import sqlite3
import pandas as pd
import json
import argparse
import sys
import os
from pathlib import Path
from datetime import timedelta

# å°è¯•è‡ªåŠ¨å®šä½é¡¹ç›®æ ¹ç›®å½• (å‡è®¾è„šæœ¬åœ¨ scripts/web/ ä¸‹)
FILE_DIR = Path(__file__).resolve().parent
PROJECT_ROOT = FILE_DIR.parents[1]  # å¾€ä¸Šè·³ä¸¤çº§åˆ°é¡¹ç›®æ ¹ç›®å½•


def get_db_path(domain, workspace_root=None):
    """æ ¹æ®é¢†åŸŸè‡ªåŠ¨æ„å»ºæ•°æ®åº“è·¯å¾„"""
    if workspace_root:
        root = Path(workspace_root)
    else:
        # å°è¯•ä»ç¯å¢ƒå˜é‡è¯»å–ï¼Œæˆ–è€…é»˜è®¤ä½¿ç”¨é¡¹ç›®ä¸‹çš„ outputs
        root = Path(os.environ.get("ABSA_WORKSPACE", PROJECT_ROOT))

    db_path = root / "outputs" / domain / "stats.db"
    return db_path


def get_product_dashboard_data(db_path):
    """è¯»å– stats.dbï¼Œç”ŸæˆæŒ‰ã€äº§å“ (Brand + Model)ã€‘ç»´åº¦çš„ç»“æ„åŒ– JSON æ•°æ®"""

    # 1. æ•°æ®åº“è·¯å¾„æ£€æŸ¥
    if not isinstance(db_path, Path):
        db_path = Path(db_path)

    if not db_path.exists():
        return {"error": f"Database not found: {db_path}"}

    # 2. è¯»å–æ•°æ®
    try:
        conn = sqlite3.connect(str(db_path))
        query = "SELECT date, brand, model, aspect, sentiment, count FROM daily_sentiment_stats"
        df = pd.read_sql(query, conn)
        conn.close()
    except Exception as e:
        return {"error": f"Database error: {str(e)}"}

    if df.empty:
        return {"error": "Database is empty"}

    # 3. æ•°æ®é¢„å¤„ç†
    df['date'] = pd.to_datetime(df['date'])
    max_date = df['date'].max()  # åŠ¨æ€é”šç‚¹æ—¶é—´ï¼ˆåŸºäºæ•°æ®ä¸­çš„æœ€åä¸€å¤©ï¼‰

    df['product_key'] = df['brand'] + " " + df['model']
    unique_products = df['product_key'].unique()

    final_output = {
        "meta": {
            "last_updated": max_date.strftime('%Y-%m-%d'),
            "data_source": str(db_path.name),
            "total_products": len(unique_products)
        },
        "products": {}
    }

    # 4. éå†äº§å“ç”Ÿæˆæ•°æ®
    for product_key in unique_products:
        df_prod = df[df['product_key'] == product_key].copy()

        product_data = {
            "brand_aspect_dist": {},
            "period_stats": {}
        }

        # --- æ¿å— 1: L1 æ–¹é¢åˆ†å¸ƒ (ä¿æŒä¸å˜) ---
        aspect_grp = df_prod.groupby(['aspect', 'sentiment'])['count'].sum().reset_index()

        def get_dist_list(sent_label):
            d = aspect_grp[aspect_grp['sentiment'] == sent_label][['aspect', 'count']].to_dict('records')
            d.sort(key=lambda x: x['count'], reverse=True)
            return d

        product_data["brand_aspect_dist"] = {
            "POS": get_dist_list("POS"),
            "NEG": get_dist_list("NEG")
        }

        # --- æ¿å— 2 & 3: å¤šæ—¶é—´çª—å£ç»Ÿè®¡ (ä¿®å¤æ ¸å¿ƒ) ---
        periods_config = {
            "last_7_days": {
                "days": 6,  # ä¿®æ­£ï¼š6å¤©å‰ + ä»Šå¤© = 7å¤©
                "rule": "D",
                "label": "day"
            },
            "last_1_month": {
                "days": 29,  # ä¿®æ­£ï¼š29å¤©å‰ + ä»Šå¤© = 30å¤©
                "rule": "W",
                "label": "week"
            },
            "last_3_months": {"days": 90, "rule": "ME", "label": "month"},
            "last_6_months": {"days": 180, "rule": "ME", "label": "month"},
            "last_12_months": {"days": 365, "rule": "ME", "label": "month"}
        }

        for p_name, cfg in periods_config.items():
            # è®¡ç®—èµ·å§‹æ—¥æœŸ
            start_date = max_date - timedelta(days=cfg['days'])
            df_period = df_prod[df_prod['date'] >= start_date].copy()

            if df_period.empty:
                product_data["period_stats"][p_name] = None
                continue

            # (1) æ€»é‡ç»Ÿè®¡
            summary_s = df_period.groupby('sentiment')['count'].sum()
            summary = {
                "POS": int(summary_s.get("POS", 0)),
                "NEG": int(summary_s.get("NEG", 0)),
                "NEU": int(summary_s.get("NEU", 0)),
                "Total": int(df_period['count'].sum())
            }

            # (2) è¶‹åŠ¿å›¾ (Resample ä¿®å¤)
            # å…ˆæŒ‰å¤©èšåˆï¼Œè§£å†³åŒä¸€å¤©å¤šæ¡è®°å½•çš„é—®é¢˜
            daily_agg = df_period.groupby(['date', 'sentiment'])['count'].sum().unstack(fill_value=0)

            # ã€æ ¸å¿ƒä¿®å¤é€»è¾‘ã€‘
            if cfg['rule'] == 'D':
                # æŒ‰å¤©èšåˆï¼Œé»˜è®¤å³å¯
                resampled = daily_agg.resample(cfg['rule']).sum().fillna(0)
            else:
                # æŒ‰å‘¨(W)æˆ–æœˆ(ME)èšåˆæ—¶ï¼Œå¼ºåˆ¶ä½¿ç”¨ label='left'
                # æ•ˆæœï¼šå‘¨èšåˆæ—¶ï¼Œæ ‡ç­¾ä¸ºâ€œæœ¬å‘¨ä¸€â€çš„æ—¥æœŸï¼Œè€Œä¸æ˜¯â€œä¸‹å‘¨æ—¥â€ï¼Œé¿å…æ—¥æœŸè¶…å‡º max_date
                resampled = daily_agg.resample(cfg['rule'], label='left', closed='left').sum().fillna(0)

            trend_list = []
            for ts, row in resampled.iterrows():
                trend_list.append({
                    "date": ts.strftime('%Y-%m-%d'),
                    "POS": int(row.get("POS", 0)),
                    "NEG": int(row.get("NEG", 0)),
                    "NEU": int(row.get("NEU", 0))
                })

            product_data["period_stats"][p_name] = {
                "granularity": cfg['label'],
                "summary": summary,
                "trend": trend_list
            }

        final_output["products"][product_key] = product_data

    return final_output

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Export product dashboard JSON from stats.db")
    parser.add_argument("--domain", required=True, help="Domain name (e.g., phone, car, laptop)")
    parser.add_argument("--workspace", default=None, help="Root workspace path (optional)")
    parser.add_argument("--output", default=None, help="Output JSON file path (optional)")

    args = parser.parse_args()

    # 1. è‡ªåŠ¨å®šä½ DB
    db_path = get_db_path(args.domain, args.workspace)
    print(f"ğŸš€ [Domain: {args.domain}] Connecting to: {db_path}")

    # 2. ç”Ÿæˆæ•°æ®
    data = get_product_dashboard_data(db_path)

    if "error" in data:
        print(f"âŒ Error: {data['error']}")
        sys.exit(1)

    # 3. ä¿å­˜ç»“æœ
    # é»˜è®¤ä¿å­˜åœ¨ outputs/{domain}/dashboard_data.jsonï¼Œæ–¹ä¾¿å‰ç«¯è¯»å–
    if args.output:
        out_path = Path(args.output)
    else:
        out_path = db_path.parent / "dashboard_data.json"

    with open(out_path, "w", encoding="utf-8") as f:
        json.dump(data, f, indent=2, ensure_ascii=False)

    print(f"âœ… Success! JSON saved to: {out_path}")