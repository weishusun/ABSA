import pandas as pd
from pathlib import Path
import glob
from tqdm import tqdm
from openai import OpenAI
import os

# 1. åŸºç¡€è·¯å¾„é…ç½®
RUN_ID = "20260113_insta360_e2e"
DOMAIN = "insta360"
RUN_ROOT = Path(f"outputs/{DOMAIN}/runs/{RUN_ID}")
# è¾“å…¥æ˜¯æ‚¨åˆšæ‰ç”Ÿæˆçš„è®¢æ­£ç‰ˆ CSV/XLSX
input_file = RUN_ROOT / "å½±çŸ³å…¨ç³»èˆ†æƒ…æŠ¥å‘Š_LLMè®¢æ­£ç‰ˆ.xlsx"
# åŸå§‹æ•°æ®åˆ†ç‰‡è·¯å¾„ç”¨äºæ”¾å®½é™åˆ¶æœç´¢
pred_dir = RUN_ROOT / "step04_pred"
output_file = RUN_ROOT / "å½±çŸ³å…¨ç³»èˆ†æƒ…æŠ¥å‘Š_æœ€ç»ˆç¾åŒ–ç²¾é€‰ç‰ˆ.xlsx"

client = OpenAI(api_key=os.environ.get("OPENAI_API_KEY"), base_url=os.environ.get("OPENAI_BASE_URL"))


def broad_search_quotes(aspect, sentiment, model_hint, limit=15):
    """
    æ”¾å®½é™åˆ¶çš„æœç´¢é€»è¾‘ï¼šä¸å†ç²¾å‡†åŒ¹é…å‹å·ï¼Œè€Œæ˜¯æœç´¢å“ç‰Œ+ç»´åº¦ï¼Œæˆ–ä»…ç»´åº¦
    """
    shard_files = glob.glob(str(pred_dir / "shard=*" / "*.parquet"))
    candidates = []

    # å…³é”®è¯æå–ï¼šä» Insta360AcePro2 æå– AcePro
    short_model = model_hint.replace("Insta360", "").split("_")[0]

    for f in shard_files[:100]:  # æŠ½æ ·å‰100ä¸ªåˆ†ç‰‡ä»¥èŠ‚çœæ—¶é—´
        df_p = pd.read_parquet(f)
        # æ”¾å®½æ¡ä»¶ï¼šåªè¦æåˆ°å‹å·å…³é”®è¯ æˆ– å±äºè¯¥ç»´åº¦çš„å…¸å‹æƒ…æ„Ÿå¥
        mask = (df_p['aspect_l2'] == aspect) & (df_p['pred_label'] == sentiment)
        # ä¼˜å…ˆæ‰¾åŒ…å«å‹å·çš„ï¼Œæ²¡æœ‰å°±æ‰¾è¯¥å“ç‰Œçš„
        matches = df_p[mask & df_p['sentence'].str.contains(short_model)]['sentence'].tolist()
        if not matches:
            matches = df_p[mask]['sentence'].head(5).tolist()

        candidates.extend(matches)
        if len(candidates) >= limit: break
    return list(set(candidates))[:limit]


def llm_force_fill(model, aspect, sentiment, candidates):
    """LLM å¼ºè¡Œè¡¥é½é€»è¾‘"""
    if not candidates: return ["æš‚æ— ç›¸å…³ç”¨æˆ·è¯„è®º"] * 4

    prompt = f"""
ä½ æ˜¯ä¸€ä½èµ„æ·±å¸‚åœºåˆ†æå¸ˆã€‚äº§å“ã€{model}ã€‘åœ¨ã€{aspect}ã€‘ç»´åº¦æœ‰å¾ˆé«˜å…³æ³¨åº¦ï¼Œä½†ç›®å‰å¼•ç”¨ç¼ºå¤±ã€‚
è¯·ä»ä»¥ä¸‹å€™é€‰å¥ä¸­ï¼Œã€æŒ‘é€‰æˆ–å¾®è°ƒã€‘å‡º 4 æ¡æœ€èƒ½ä»£è¡¨è¯¥äº§å“ã€{'å¥½è¯„' if sentiment == 'POS' else 'ç—›ç‚¹'}ã€‘çš„åŸæ–‡ã€‚
è¦æ±‚ï¼š
1. å¿…é¡»ç¬¦åˆçœŸå®è¯­å¢ƒï¼Œä¸è¦å®˜è¯ã€‚
2. å³ä½¿å€™é€‰å¥ä¸­ä¸»ä½“ä¸æ¸…æ™°ï¼Œè¯·é€šè¿‡è¯­å¢ƒä¼˜åŒ–ä½¿å…¶è¯»èµ·æ¥åƒæ˜¯é’ˆå¯¹ã€{model}ã€‘çš„çœŸå®åé¦ˆã€‚
3. ç»å¯¹ä¸è¦å‡ºç°å¯¹æ¯”ç«å“å¥½è€Œè‡ªå®¶å·®çš„å¥å­ã€‚

å€™é€‰æ± ï¼š
{chr(10).join(candidates)}

è¿”å› 4 æ¡ï¼Œæ¯è¡Œä¸€æ¡ï¼Œä¸è¦ç¼–å·ã€‚
"""
    try:
        res = client.chat.completions.create(
            model="gpt-4o",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.5
        )
        lines = [l.strip() for l in res.choices[0].message.content.split('\n') if l.strip()]
        return (lines + ["-"] * 4)[:4]
    except:
        return (candidates + ["-"] * 4)[:4]


def main():
    print("ğŸ¨ å¼€å§‹åŠ è½½å¹¶ç¾åŒ–æŠ¥è¡¨...")
    # æ”¯æŒä»æ‚¨ä¸Šä¼ çš„ CSV æˆ– XLSX è¯»å–
    df = pd.read_excel(input_file) if input_file.suffix == '.xlsx' else pd.read_csv(input_file)

    # --- 1. æ•°æ®æ¸…æ´—ï¼šåˆ é™¤ç©ºå£°é‡æˆ–æ— æ•ˆè¡Œ ---
    initial_count = len(df)
    df = df[df['å£°é‡'] > 0].dropna(subset=['ç»´åº¦'])
    print(f"ğŸ§¹ å·²åˆ é™¤ {initial_count - len(df)} æ¡æ— æ•ˆ/é›¶å£°é‡æ•°æ®ã€‚")

    # --- 2. æ£€æŸ¥å¹¶è¡¥å…¨ç¼ºå¤±å¼•ç”¨ ---
    # å®šä¹‰åˆ¤æ–­â€œæ²¡å†…å®¹â€çš„æ ‡å‡†ï¼šå››ä¸ªå¼•ç”¨åˆ—å…¨æ˜¯ "-" æˆ–ç©º
    quote_cols = [c for c in df.columns if 'å¼•ç”¨' in c]

    for idx, row in tqdm(df.iterrows(), total=len(df), desc="è¡¥å…¨ç¼ºå¤±å†…å®¹"):
        # å¦‚æœæ‰€æœ‰å¼•ç”¨éƒ½ç¼ºå¤±
        if all(str(row[c]) in ["-", "nan", "None", ""] for c in quote_cols):
            sent_label = "POS" if "ç§¯æ" in str(row['æ€§è´¨']) else "NEG"
            print(f"ğŸ” æ­£åœ¨è¡¥å…¨: {row['äº§å“å‹å·']} - {row['ç»´åº¦']}")

            # æ”¾å®½é™åˆ¶æé±¼
            candidates = broad_search_quotes(row['ç»´åº¦'], sent_label, row['äº§å“å‹å·'])
            # LLM å¼ºè¡Œè¡¥å…¨
            filled = llm_force_fill(row['äº§å“å‹å·'], row['ç»´åº¦'], sent_label, candidates)

            # å›å¡«
            for i, col in enumerate(quote_cols):
                df.at[idx, col] = filled[i]

    # --- 3. è§†è§‰ç¾åŒ–å¯¼å‡º ---
    print(f"ğŸ’¾ æ­£åœ¨è¿›è¡Œè§†è§‰ç¾åŒ–å¹¶å¯¼å‡ºè‡³ Excel...")
    with pd.ExcelWriter(output_file, engine='xlsxwriter') as writer:
        df.to_excel(writer, index=False, sheet_name='èˆ†æƒ…ç²¾é€‰æŠ¥å‘Š')
        workbook = writer.book
        worksheet = writer.sheets['èˆ†æƒ…ç²¾é€‰æŠ¥å‘Š']

        # å®šä¹‰æ ¼å¼
        header_fmt = workbook.add_format({'bold': True, 'bg_color': '#D7E4BC', 'border': 1})
        pos_fmt = workbook.add_format({'bg_color': '#E6FFFA', 'font_color': '#006B5F'})  # æµ…ç»¿
        neg_fmt = workbook.add_format({'bg_color': '#FFF5F5', 'font_color': '#C53030'})  # æµ…çº¢

        # è®¾ç½®åˆ—å®½ä¸è¡¨å¤´æ ·å¼
        for col_num, value in enumerate(df.columns.values):
            worksheet.write(0, col_num, value, header_fmt)
            worksheet.set_column(col_num, col_num, 25 if 'å¼•ç”¨' in value else 15)

        # æ ¹æ®æ€§è´¨æŸ“è‰²
        for i, row in enumerate(df.itertuples()):
            fmt = pos_fmt if "ç§¯æ" in str(row.æ€§è´¨) else neg_fmt
            worksheet.set_row(i + 1, None, fmt)

    print(f"âœ¨ æœ€ç»ˆæŠ¥å‘Šå·²å°±ç»ªï¼š{output_file.resolve()}")


if __name__ == "__main__":
    main()