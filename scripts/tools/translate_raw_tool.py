# scripts/tools/translate_raw_tool.py
import argparse
import json
import os
import time
from concurrent.futures import ThreadPoolExecutor, as_completed
from pathlib import Path
from typing import List, Dict
import random

from openai import OpenAI
from tqdm import tqdm
from dotenv import load_dotenv

load_dotenv()

# --- ç³»ç»Ÿæç¤ºè¯ ---
SYSTEM_PROMPT = (
    "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ç¿»è¯‘åŠ©æ‰‹ã€‚è¯·å°†ç”¨æˆ·æä¾›çš„JSONåˆ—è¡¨ä¸­çš„ content å­—æ®µå†…å®¹ç¿»è¯‘æˆæµç•…çš„ä¸­æ–‡ã€‚\n"
    "è¦æ±‚ï¼š\n"
    "1. ä¿æŒåŸæ–‡çš„è¯­æ°”ã€æƒ…æ„Ÿè‰²å½©å’Œä¸“ä¸šæœ¯è¯­ã€‚\n"
    "2. ä»…è¾“å‡ºç¿»è¯‘åçš„ç»“æœåˆ—è¡¨ï¼Œä¿æŒJSONæ ¼å¼ï¼Œkey ä¾ç„¶ä¸º 'id' å’Œ 'content'ã€‚\n"
    "3. å¦‚æœåŸæ–‡å·²ç»æ˜¯ä¸­æ–‡ï¼Œåˆ™åŸæ ·ä¿ç•™ã€‚\n"
    "4. ä¸è¦è¾“å‡ºä»»ä½•Markdownæ ‡è®°æˆ–è§£é‡Šï¼Œåªè¾“å‡ºçº¯JSONå­—ç¬¦ä¸²ã€‚"
)


def parse_args():
    parser = argparse.ArgumentParser(description="å‰ç½®å·¥å…·ï¼šå°†å¤–è¯­ JSONL æ•°æ®ç¿»è¯‘ä¸ºä¸­æ–‡ (å¤šçº¿ç¨‹ç‰ˆ + JSONè¾“å‡º)")
    parser.add_argument("--input", required=True, help="è¾“å…¥æ–‡ä»¶è·¯å¾„")
    parser.add_argument("--output", required=True, help="è¾“å‡ºæ–‡ä»¶è·¯å¾„")
    parser.add_argument("--content-key", default="content", help="éœ€ç¿»è¯‘çš„å­—æ®µå")
    parser.add_argument("--id-key", default="id", help="å”¯ä¸€IDå­—æ®µå")
    parser.add_argument("--model", default="gpt-3.5-turbo", help="æ¨¡å‹åç§°")
    parser.add_argument("--base-url", default=None, help="API Base URL")
    parser.add_argument("--api-key", default=None, help="API Key")
    parser.add_argument("--batch-size", type=int, default=3, help="Batch Size")
    parser.add_argument("--threads", type=int, default=5, help="å¹¶å‘çº¿ç¨‹æ•°")
    return parser.parse_args()


def call_llm_translate(client: OpenAI, model: str, batch: List[Dict], content_key: str, id_key: str, retry=3) -> List[
    Dict]:
    """
    è°ƒç”¨ LLM ç¿»è¯‘ (å·²åŒ…å« max_tokens=4096 ä¿®å¤)
    """
    mini_batch = [{"id": item.get(id_key), "content": item.get(content_key, "")} for item in batch]
    mini_batch = [x for x in mini_batch if x["content"] and len(str(x["content"]).strip()) > 1]

    if not mini_batch:
        return batch

    input_str = json.dumps(mini_batch, ensure_ascii=False)

    for attempt in range(retry):
        try:
            resp = client.chat.completions.create(
                model=model,
                messages=[
                    {"role": "system", "content": SYSTEM_PROMPT},
                    {"role": "user", "content": input_str}
                ],
                temperature=0.3,
                max_tokens=4096  # <--- [å…³é”®ä¿®å¤] é˜²æ­¢é•¿æ–‡è¢«æˆªæ–­
            )
            raw_content = resp.choices[0].message.content.strip()

            if raw_content.startswith("```json"): raw_content = raw_content[7:]
            if raw_content.endswith("```"): raw_content = raw_content[:-3]

            translated_list = json.loads(raw_content)

            trans_map = {str(t.get("id")): t.get("content") for t in translated_list}
            result_batch = []
            for item in batch:
                item_id = str(item.get(id_key))
                new_item = item.copy()
                if item_id in trans_map:
                    new_item[content_key] = trans_map[item_id]
                result_batch.append(new_item)

            return result_batch

        except Exception as e:
            if "json" in str(e).lower():
                print(f"[WARN] JSON è§£æå¤±è´¥(å¯èƒ½æˆªæ–­)ï¼Œé‡è¯• {attempt + 1}/{retry}...")
            elif "429" in str(e):
                time.sleep((attempt + 1) * 3)
            else:
                print(f"[ERROR] API: {e}")

            if attempt == retry - 1:
                return batch

    return batch


def main():
    args = parse_args()
    api_key = args.api_key or os.environ.get("OPENAI_API_KEY")
    base_url = args.base_url or os.environ.get("OPENAI_BASE_URL")

    if not api_key:
        print("[FATAL] ç¼ºå°‘ API Key")
        return

    client = OpenAI(api_key=api_key, base_url=base_url)

    input_path = Path(args.input)
    output_path = Path(args.output)

    # 1. è¯»å–è¾“å…¥ (å…¼å®¹ JSON å’Œ JSONL)
    all_lines = []
    try:
        with open(input_path, 'r', encoding='utf-8') as f:
            first_char = f.read(1)
            f.seek(0)
            if first_char == '[':  # æ ‡å‡† JSON
                all_lines = json.load(f)
            else:  # JSONL
                for line in f:
                    if line.strip(): all_lines.append(json.loads(line))
    except Exception as e:
        print(f"[ERROR] è¯»å–æ–‡ä»¶å¤±è´¥: {e}")
        return

    total = len(all_lines)
    print(f"ğŸ“Š æ€»æ•°æ®é‡: {total} æ¡")
    if total == 0: return

    batch_size = args.batch_size
    batches = [all_lines[i:i + batch_size] for i in range(0, total, batch_size)]

    # --- 2. ç¿»è¯‘è¿‡ç¨‹ (ä½¿ç”¨ä¸´æ—¶æ–‡ä»¶) ---
    # ä¸ºäº†å®‰å…¨ï¼Œå…ˆå†™ä¸€ä¸ª temp.jsonlï¼Œå…¨éƒ¨è·‘å®Œå†è½¬æˆ json
    temp_output = output_path.with_suffix(".temp.jsonl")

    # æ¸…ç©ºä¸´æ—¶æ–‡ä»¶
    with open(temp_output, 'w', encoding='utf-8') as f:
        pass

    print(f"ğŸš€ å¯åŠ¨å¤šçº¿ç¨‹ç¿»è¯‘ (Results -> {temp_output})...")

    max_workers = args.threads

    with ThreadPoolExecutor(max_workers=max_workers) as executor:
        future_to_batch = {
            executor.submit(call_llm_translate, client, args.model, batch, args.content_key, args.id_key): batch
            for batch in batches
        }

        with tqdm(total=total, unit="row") as pbar:
            for future in as_completed(future_to_batch):
                try:
                    result_batch = future.result()
                    # å®æ—¶å†™å…¥ä¸´æ—¶æ–‡ä»¶ (JSONL)
                    with open(temp_output, 'a', encoding='utf-8') as f:
                        for item in result_batch:
                            f.write(json.dumps(item, ensure_ascii=False) + "\n")
                    pbar.update(len(result_batch))
                except Exception as e:
                    print(f"çº¿ç¨‹å¼‚å¸¸: {e}")
                    pbar.update(batch_size)

    # --- 3. æ ¼å¼è½¬æ¢ (JSONL -> JSON) ---
    print("ğŸ”„ æ­£åœ¨æ•´åˆç»“æœä¸ºæ ‡å‡† JSON æ ¼å¼...")
    final_data = []
    if temp_output.exists():
        with open(temp_output, 'r', encoding='utf-8') as f:
            for line in f:
                if line.strip():
                    final_data.append(json.loads(line))

        # å†™å…¥æœ€ç»ˆ JSON æ–‡ä»¶
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(final_data, f, ensure_ascii=False, indent=2)  # indent=2 è®©æ–‡ä»¶å¯è¯»æ€§æ›´å¥½

        print(f"âœ… æˆåŠŸï¼æ–‡ä»¶å·²ä¿å­˜: {output_path}")

        # åˆ é™¤ä¸´æ—¶æ–‡ä»¶
        try:
            os.remove(temp_output)
        except:
            pass
    else:
        print("âŒ é”™è¯¯ï¼šæœªç”Ÿæˆä¸´æ—¶æ–‡ä»¶ï¼Œä»»åŠ¡å¯èƒ½å¤±è´¥ã€‚")


if __name__ == "__main__":
    main()