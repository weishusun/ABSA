import streamlit as st
import pandas as pd
import plotly.express as px
import subprocess
import os
import sys
import collections
import re
import time
import yaml
import shutil
import json
import difflib
import sqlite3
from pathlib import Path
import datetime

# --- 0. ä¾èµ–æ£€æŸ¥ ---
try:
    import jieba

    HAS_JIEBA = True
except ImportError:
    HAS_JIEBA = False

# --- 1. å…¨å±€é…ç½®ä¸æ ·å¼ ---
st.set_page_config(
    page_title="ABSA èˆ†æƒ…åˆ†æç³»ç»Ÿ",
    layout="wide",
    page_icon="âš¡",
    initial_sidebar_state="expanded"
)

st.markdown("""
<style>
    /* å…¨å±€å­—ä½“ä¸é‡ç½® */
    .stApp { font-family: "Inter", system-ui, sans-serif; }
    /* ä¾§è¾¹æ ä¼˜åŒ– */
    [data-testid="stSidebar"] { background-color: #f8f9fa; border-right: 1px solid #e9ecef; }
    /* æ ‡é¢˜æ ·å¼ */
    h1 { font-weight: 700 !important; color: #111827; }
    h2, h3 { font-weight: 600 !important; color: #374151; }
    /* å¡ç‰‡å®¹å™¨å¢å¼º */
    [data-testid="stVerticalBlockBorderWrapper"] {
        border-radius: 0.75rem;
        box-shadow: 0 1px 3px 0 rgb(0 0 0 / 0.1);
        background-color: white;
        padding: 1rem;
    }
    /* è¿›åº¦æ¡é¢œè‰²å“ç‰ŒåŒ– */
    .stProgress > div > div > div > div { background-color: #3b82f6; }
    /* ä»£ç å—å­—ä½“ */
    code { font-family: 'JetBrains Mono', monospace; }
</style>
""", unsafe_allow_html=True)

# --- 2. åŠ¨æ€è·¯å¾„åˆå§‹åŒ– ---
ROOT = Path(__file__).resolve().parent
CONFIGS_DIR = ROOT / "configs" / "domains"
python_exe = sys.executable

# --- 3. ä¾§è¾¹æ ï¼šæ ¸å¿ƒé…ç½®åŒº ---
with st.sidebar:
    st.title("âš™ï¸ ç³»ç»Ÿé…ç½®")

    with st.container(border=True):
        st.subheader("1. å·¥ä½œåŒºè®¾ç½®")
        default_ws = os.environ.get("ABSA_WORKSPACE", str(ROOT / "workspace_data"))
        user_ws_input = st.text_input("æ•°æ®å­˜æ”¾ç›®å½• (Workspace)", value=default_ws,
                                      help="æ‰€æœ‰è¾“å…¥/è¾“å‡ºæ•°æ®å°†å­˜æ”¾åœ¨æ­¤ç›®å½•ä¸‹")
        WORKSPACE = Path(user_ws_input).resolve()
        INPUTS_DIR = WORKSPACE / "inputs"
        OUTPUTS_DIR = WORKSPACE / "outputs"

        if not WORKSPACE.exists():
            st.warning("âš ï¸ ç›®å½•ä¸å­˜åœ¨")
            if st.button("åˆ›å»ºå·¥ä½œåŒºæ–‡ä»¶å¤¹"):
                try:
                    INPUTS_DIR.mkdir(parents=True, exist_ok=True)
                    OUTPUTS_DIR.mkdir(parents=True, exist_ok=True)
                    st.success("âœ… å·²åˆ›å»ºï¼")
                    time.sleep(0.5)
                    st.rerun()
                except Exception as e:
                    st.error(f"åˆ›å»ºå¤±è´¥: {e}")
        else:
            st.caption(f"âœ… çŠ¶æ€: å·²è¿æ¥")

    st.markdown("---")

    with st.container(border=True):
        st.subheader("2. ä»»åŠ¡å‚æ•°")
        domain = st.selectbox("ğŸ“¦ é¢†åŸŸ (Domain)", ["car", "phone", "laptop", "beauty"], index=0)
        run_id = st.text_input("ğŸ·ï¸ ä»»åŠ¡æ ‡è¯† (Run ID)", value="prod_v1_full")

    st.markdown("---")

    # ==================== æ™ºèƒ½ LLM é…ç½®ç‰ˆ ====================
    with st.container(border=True):
        st.subheader("3. ğŸ§  LLM æ¨¡å‹é…ç½®")

        LLM_PRESETS = {
            "OpenAI (å®˜æ–¹)": {"base_url": "https://api.openai.com/v1", "models": ["gpt-4o-mini", "gpt-4o"]},
            "DeepSeek (æ·±åº¦æ±‚ç´¢)": {"base_url": "https://api.deepseek.com",
                                    "models": ["deepseek-chat", "deepseek-coder"]},
            "Moonshot (Kimi)": {"base_url": "https://api.moonshot.cn/v1", "models": ["moonshot-v1-8k"]},
            "Aliyun (é€šä¹‰åƒé—®)": {"base_url": "https://dashscope.aliyuncs.com/compatible-mode/v1",
                                  "models": ["qwen-plus"]},
            "è‡ªå®šä¹‰ (Custom)": {"base_url": "", "models": []}
        }

        with st.expander("é…ç½®è¯¦æƒ… (ç‚¹å‡»å±•å¼€)", expanded=False):
            provider = st.selectbox("API æœåŠ¡å•†", options=list(LLM_PRESETS.keys()), index=1)
            selected_preset = LLM_PRESETS[provider]

            env_key = os.environ.get("OPENAI_API_KEY", "")
            user_key = st.text_input("API Key", value=env_key, type="password", key="idx_api_key")

            default_base = selected_preset["base_url"]
            if provider == "è‡ªå®šä¹‰ (Custom)" and os.environ.get("OPENAI_BASE_URL"):
                default_base = os.environ.get("OPENAI_BASE_URL")

            user_base_raw = st.text_input("Base URL", value=default_base, key=f"idx_base_url_{provider}")
            user_base = re.sub(r"[\[\]\(\)]", "", user_base_raw).split("http")[-1]
            if user_base: user_base = "http" + user_base.strip()

            if provider == "è‡ªå®šä¹‰ (Custom)":
                default_model = os.environ.get("OPENAI_MODEL_NAME", "")
                user_model = st.text_input("æ¨¡å‹åç§°", value=default_model)
            else:
                model_options = selected_preset["models"] + ["ğŸ“ æ‰‹åŠ¨è¾“å…¥..."]
                selected_model_opt = st.selectbox("é€‰æ‹©æ¨¡å‹", model_options, key=f"idx_model_sel_{provider}")
                user_model = st.text_input("è¯·è¾“å…¥æ¨¡å‹åç§°",
                                           value="") if selected_model_opt == "ğŸ“ æ‰‹åŠ¨è¾“å…¥..." else selected_model_opt

            if user_key: os.environ["OPENAI_API_KEY"] = user_key.strip()
            if user_base: os.environ["OPENAI_BASE_URL"] = user_base.strip()
            if user_model: os.environ["OPENAI_MODEL_NAME"] = user_model.strip()

            if st.button("ğŸ”Œ æµ‹è¯•è¿æ¥", use_container_width=True):
                if not user_key:
                    st.error("è¯·å…ˆå¡«å†™ API Key")
                else:
                    try:
                        from openai import OpenAI

                        with st.spinner(f"æ­£åœ¨è¿æ¥ {provider}..."):
                            client = OpenAI(api_key=user_key, base_url=user_base)
                            resp = client.chat.completions.create(model=user_model,
                                                                  messages=[{"role": "user", "content": "Hi"}],
                                                                  max_tokens=5)
                            st.toast(f"âœ… è¿æ¥æˆåŠŸ! {resp.choices[0].message.content}", icon="ğŸŸ¢")
                    except Exception as e:
                        st.error(f"âŒ è¿æ¥å¤±è´¥: {e}")

    st.markdown("---")
    page = st.radio("æµç¨‹å¯¼èˆª", ["0ï¸âƒ£ æ•°æ®å‡†å¤‡", "1ï¸âƒ£ è¦†ç›–ç‡å®éªŒå®¤", "2ï¸âƒ£ è®­ç»ƒä¸æ¨ç†", "3ï¸âƒ£ æ•°æ®çœ‹æ¿ (DBç‰ˆ)"])


# --- 4. æ ¸å¿ƒå·¥å…·å‡½æ•° ---
def get_files(domain):
    base = OUTPUTS_DIR / domain
    config_path = CONFIGS_DIR / domain / "aspects.yaml"
    return {
        "raw_dir": INPUTS_DIR,
        "clean": base / "clean_sentences.parquet",
        "aspect": base / "aspect_sentences.parquet",
        "config": config_path,
        "excel": base / "runs",
        "db": base / "stats.db"  # æ–°å¢æ•°æ®åº“è·¯å¾„
    }


def run_command_with_progress(cmd_list, desc="æ‰§è¡Œä»»åŠ¡ä¸­..."):
    with st.status(desc, expanded=True) as status:
        st.write(f"ğŸ”§ **Command:** `{' '.join(cmd_list)}`")
        progress_bar = st.progress(0)
        log_area = st.empty()
        logs = []

        env = os.environ.copy()
        env["ABSA_WORKSPACE"] = str(WORKSPACE)
        env["PYTHONIOENCODING"] = "utf-8"

        try:
            process = subprocess.Popen(cmd_list, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True,
                                       encoding='utf-8', errors='replace', cwd=str(ROOT), env=env)
            line_count = 0
            while True:
                line = process.stdout.readline()
                if not line and process.poll() is not None: break
                if line:
                    clean_line = line.strip()
                    logs.append(clean_line)
                    line_count += 1
                    log_area.code("\n".join(logs[-8:]), language="bash")
                    print(clean_line, flush=True)
                    current_prog = min(95, int((line_count % 100) + (line_count / 200)))
                    progress_bar.progress(current_prog)
            process.wait()
            progress_bar.progress(100)
            if process.returncode == 0:
                status.update(label="âœ… ä»»åŠ¡å®Œæˆ", state="complete", expanded=False)
                return True
            else:
                status.update(label="âŒ ä»»åŠ¡å¤±è´¥", state="error", expanded=True)
                return False
        except Exception as e:
            st.error(f"æ— æ³•å¯åŠ¨è¿›ç¨‹: {e}")
            return False


@st.cache_data(ttl=60)
def analyze_coverage(clean_path, aspect_path):
    if not clean_path.exists() or not aspect_path.exists(): return None, None, None
    try:
        df_clean = pd.read_parquet(clean_path)
        df_aspect = pd.read_parquet(aspect_path)
    except:
        return None, None, None

    total = len(df_clean)
    if total == 0: return 0.0, [], pd.DataFrame()

    clean_col = next((col for col in ['text', 'sentence', 'content'] if col in df_clean.columns), None)
    aspect_col = next((col for col in ['text', 'sentence', 'content'] if col in df_aspect.columns), None)
    id_col = next((col for col in ['sentence_id', 'id', 'row_id'] if col in df_clean.columns), None)

    df_uncovered = pd.DataFrame()
    if id_col and id_col in df_aspect.columns:
        covered_ids = set(df_aspect[id_col].unique())
        df_uncovered = df_clean[~df_clean[id_col].isin(covered_ids)].copy()
    elif clean_col and aspect_col:
        covered_texts = set(df_aspect[aspect_col].unique())
        df_uncovered = df_clean[~df_clean[clean_col].isin(covered_texts)].copy()

    coverage = (total - len(df_uncovered)) / total
    suggestions = []
    if not df_uncovered.empty and clean_col:
        sample_text = df_uncovered[clean_col].dropna().head(2000).astype(str).tolist()
        text_corpus = " ".join(sample_text)
        words = jieba.cut(text_corpus) if HAS_JIEBA else re.split(r'\W+', text_corpus)
        stopwords = {'è¿™ä¸ª', 'é‚£ä¸ª', 'the', 'and', 'not'}
        words = [w for w in words if len(w) > 1 and w not in stopwords]
        suggestions = collections.Counter(words).most_common(30)

    return coverage, suggestions, df_uncovered


paths = get_files(domain)

# -----------------------------------------------------------------------------
# 0ï¸âƒ£ æ•°æ®å‡†å¤‡ (æ–°å¢ç¿»è¯‘åŠŸèƒ½)
# -----------------------------------------------------------------------------
if page == "0ï¸âƒ£ æ•°æ®å‡†å¤‡":
    st.title("ğŸ—‚ï¸ Step 00: æ•°æ®å‡†å¤‡ & ç¿»è¯‘")
    current_domain_input_dir = INPUTS_DIR / domain

    # æ–°å¢ Tabs
    tab_trans, tab_clean = st.tabs(["ğŸŒ è¾…åŠ©å·¥å…·: æ•°æ®ç¿»è¯‘", "ğŸ§¹ æ ¸å¿ƒæµç¨‹: æ¸…æ´—ä¸æ ‡å‡†åŒ–"])

    # --- Tab 1: æ‰¹é‡ç¿»è¯‘å·¥å…· (æ”¯æŒå®æ—¶æ—¥å¿—æ»šåŠ¨) ---
    with tab_trans:
        st.subheader("ğŸŒ æ‰¹é‡æ•°æ®ç¿»è¯‘")
        st.info("è‡ªåŠ¨æ‰«ææŒ‡å®šç›®å½•ä¸‹çš„æ‰€æœ‰ JSON/JSONL æ–‡ä»¶ï¼Œå¹¶æ‰¹é‡è°ƒç”¨ LLM è¿›è¡Œç¿»è¯‘ã€‚")

        # 1. è®¾ç½®æºç›®å½•
        default_trans_dir = WORKSPACE / "Translation"
        scan_dir_input = st.text_input("ğŸ“‚ ç¿»è¯‘æºç›®å½• (ç»“æœä¹Ÿå°†ä¿å­˜åœ¨æ­¤æ ¹ç›®å½•ä¸‹)",
                                       value=str(default_trans_dir))
        scan_path = Path(scan_dir_input)

        # 2. æ‰«ææ–‡ä»¶
        found_files = []
        if scan_path.exists():
            found_files.extend(list(scan_path.rglob("*.json")))
            found_files.extend(list(scan_path.rglob("*.jsonl")))

        # --- ğŸ•µï¸ æ•°æ®ä¾¦æ¢ ---
        suggested_content_key = "content"
        suggested_id_key = "id"
        preview_data = None
        if found_files:
            try:
                sample_file = found_files[0]
                with open(sample_file, 'r', encoding='utf-8') as f:
                    first_char = f.read(1)
                    f.seek(0)
                    if first_char == '[' or first_char == '{':
                        try:
                            data = json.load(f)
                            if isinstance(data, dict):
                                for k, v in data.items():
                                    if isinstance(v, list) and len(v) > 0 and isinstance(v[0], dict):
                                        preview_data = v[0];
                                        break
                                if not preview_data: preview_data = data
                            elif isinstance(data, list) and len(data) > 0:
                                preview_data = data[0]
                        except:
                            pass
                    if not preview_data:
                        line = f.readline()
                        preview_data = json.loads(line)
                if preview_data:
                    keys = list(preview_data.keys())
                    for k in ['content', 'text', 'body', 'review', 'comment', 'detail']:
                        if k in keys: suggested_content_key = k; break
                    for k in ['id', 'review_id', 'comment_id', 'uuid', 'row_id']:
                        if k in keys: suggested_id_key = k; break
                    st.success(f"âœ… è‡ªåŠ¨ä¾¦æµ‹æˆåŠŸï¼å·²æ ¹æ® `{sample_file.name}` åŒ¹é…å­—æ®µã€‚")
                    with st.expander("ğŸ•µï¸ æŸ¥çœ‹æºæ•°æ®æ ·æœ¬ (ç‚¹å‡»å±•å¼€)", expanded=False):
                        st.json(preview_data)
            except Exception as e:
                st.warning(f"æ— æ³•é¢„è§ˆæ•°æ®ç»“æ„: {e}")

        # --------------------------------
        if not found_files:
            if not scan_path.exists():
                st.warning(f"ç›®å½•ä¸å­˜åœ¨: {scan_path}")
            else:
                st.warning("è¯¥ç›®å½•ä¸‹æœªæ‰¾åˆ° .json æˆ– .jsonl æ–‡ä»¶")
        else:
            st.write(f"ğŸ“Š å…±å‘ç° {len(found_files)} ä¸ªæ–‡ä»¶")
            c1, c2 = st.columns(2)
            with c1:
                content_key = st.text_input("å†…å®¹å­—æ®µå (Content Key)", value=suggested_content_key)
            with c2:
                id_key = st.text_input("ID å­—æ®µå (ID Key)", value=suggested_id_key)

            if st.button("ğŸš€ å¼€å§‹æ‰¹é‡ç¿»è¯‘", type="primary"):
                if not os.environ.get("OPENAI_API_KEY"):
                    st.error("âŒ è¯·å…ˆåœ¨å·¦ä¾§ä¾§è¾¹æ é…ç½® API Keyï¼")
                else:
                    target_output_dir = scan_path
                    progress_bar = st.progress(0)
                    success_files = []

                    # ä½¿ç”¨ st.status åŒ…è£¹æ•´ä¸ªæ‰¹é‡ä»»åŠ¡
                    with st.status("æ­£åœ¨æ‰§è¡Œæ‰¹é‡ç¿»è¯‘ä»»åŠ¡...", expanded=True) as status:
                        log_container = st.empty()  # åˆ›å»ºä¸€ä¸ªç©ºçš„å®¹å™¨ç”¨äºæ˜¾ç¤ºæ»šåŠ¨æ—¥å¿—

                        for idx, src_file in enumerate(found_files):
                            parent_name = src_file.parent.name
                            safe_name = f"{parent_name}_{src_file.stem}.json"
                            target_file = target_output_dir / safe_name

                            status.update(label=f"ğŸ”„ [{idx + 1}/{len(found_files)}] æ­£åœ¨å¤„ç†: {src_file.name}")
                            st.write(f"ğŸ“„ æ–‡ä»¶: `{src_file.name}` -> `{safe_name}`")

                            cmd = [
                                python_exe, "-u", str(ROOT / "scripts" / "tools" / "translate_raw_tool.py"),
                                "--input", str(src_file),
                                "--output", str(target_file),
                                "--content-key", content_key,
                                "--id-key", id_key,
                                "--model", os.environ.get("OPENAI_MODEL_NAME", "deepseek-chat"),
                                "--base-url", os.environ.get("OPENAI_BASE_URL", "https://api.deepseek.com"),
                                "--api-key", os.environ.get("OPENAI_API_KEY"),
                                "--batch-size", "2"
                            ]

                            env = os.environ.copy()
                            env["PYTHONIOENCODING"] = "utf-8"

                            # [å…³é”®ä¿®æ”¹] ä½¿ç”¨ Popen å®ç°å®æ—¶æ—¥å¿—æµ
                            try:
                                process = subprocess.Popen(
                                    cmd,
                                    stdout=subprocess.PIPE,
                                    stderr=subprocess.STDOUT,  # å°†é”™è¯¯æ—¥å¿—ä¹Ÿåˆå¹¶åˆ°è¾“å‡ºæµ
                                    text=True,
                                    encoding='utf-8',
                                    errors='replace',
                                    env=env,
                                    bufsize=1  # è¡Œç¼“å†²ï¼Œç¡®ä¿å®æ—¶è¾“å‡º
                                )

                                # å®æ—¶è¯»å–æ—¥å¿—
                                recent_logs = []
                                while True:
                                    line = process.stdout.readline()
                                    if not line and process.poll() is not None:
                                        break
                                    if line:
                                        clean_line = line.strip()
                                        if clean_line:
                                            recent_logs.append(clean_line)
                                            # åªä¿ç•™æœ€å 15 è¡Œï¼Œé˜²æ­¢ç•Œé¢å¡é¡¿
                                            if len(recent_logs) > 15:
                                                recent_logs.pop(0)
                                            # å®æ—¶åˆ·æ–°æ—¥å¿—æ¡†
                                            log_container.code("\n".join(recent_logs), language="bash")

                                if process.returncode == 0:
                                    success_files.append(target_file)
                                else:
                                    st.error(f"âŒ æ–‡ä»¶ {src_file.name} ç¿»è¯‘å¤±è´¥")

                            except Exception as e:
                                st.error(f"å¯åŠ¨è¿›ç¨‹å¤±è´¥: {e}")

                            progress_bar.progress((idx + 1) / len(found_files))

                        status.update(label=f"âœ… ä»»åŠ¡å®Œæˆï¼æˆåŠŸ: {len(success_files)}/{len(found_files)}",
                                      state="complete")

                    if success_files:
                        st.divider()
                        st.subheader("ğŸ‘€ ç»“æœéªŒè¯ (Verification)")
                        st.success(f"ğŸ‰ ç¿»è¯‘å®Œæˆï¼æ–‡ä»¶å·²ä¿å­˜åœ¨: `{target_output_dir}`")

                        last_file = success_files[-1]
                        st.write(f"**ğŸ” æŠ½æ£€æ–‡ä»¶:** `{last_file.name}`")

                        try:
                            # ä¿®æ”¹è¯»å–é€»è¾‘ä»¥æ”¯æŒæ ‡å‡† JSON
                            with open(last_file, 'r', encoding='utf-8') as f:
                                # JSON æ–‡ä»¶ä¸èƒ½æŒ‰è¡Œè¯»ï¼Œç›´æ¥ load å‰å‡ ä¸ªå³å¯
                                data = json.load(f)
                                preview_lines = data[:3]  # å–å‰3ä¸ª

                            if preview_lines:
                                st.caption("ğŸ‘‡ ä»¥ä¸‹æ˜¯è¯¥æ–‡ä»¶çš„å‰ 3 æ¡ç¿»è¯‘ç»“æœï¼Œè¯·æ£€æŸ¥ä¸­æ–‡æ˜¯å¦æ­£å¸¸ï¼š")
                                st.json(preview_lines)
                        except Exception as e:
                            st.error(f"æ— æ³•è¯»å–é¢„è§ˆæ–‡ä»¶: {e}")
    # --- Tab 2: åŸæœ‰æ¸…æ´—æµç¨‹ ---
    with tab_clean:
        with st.container(border=True):
            col1, col2 = st.columns([1, 1])
            with col1:
                st.subheader("1. æ‰«æä¸æ¸…æ´—")
                scan_dir_input = st.text_input("æ‰«æç›®æ ‡å­ç›®å½•", value=str(current_domain_input_dir))
                scan_path = Path(scan_dir_input)
                valid_files = []

                if scan_path.exists():
                    found_files = list(scan_path.rglob('*.*'))
                    valid_files = [f for f in found_files if f.suffix in ['.json', '.jsonl', '.txt']]
                    if valid_files:
                        st.success(f"âœ… å‘ç° {len(valid_files)} ä¸ªæºæ–‡ä»¶")
                        with st.expander("æŸ¥çœ‹æ–‡ä»¶åˆ—è¡¨"):
                            st.write([f.name for f in valid_files])
                    else:
                        st.warning("âš ï¸ è¯¥ç›®å½•ä¸‹ä¸ºç©ºæˆ–æ²¡æœ‰æ”¯æŒçš„æ–‡ä»¶æ ¼å¼")
                else:
                    st.error("âŒ ç›®å½•ä¸å­˜åœ¨")
                    if st.button(f"åˆ›å»ºæ–‡ä»¶å¤¹: {domain}"):
                        scan_path.mkdir(parents=True, exist_ok=True)
                        st.rerun()

                if valid_files:
                    target_output_file = OUTPUTS_DIR / domain / "clean_sentences.parquet"
                    force_overwrite = st.checkbox("å¼ºåˆ¶è¦†ç›– (æ¸…é™¤æ—§æ•°æ®)", value=True)

                    if st.button("â–¶ï¸ å¼€å§‹æ¸…æ´— (Run Step 00)", type="primary", use_container_width=True):
                        if force_overwrite and target_output_file.exists():
                            try:
                                target_output_file.unlink()
                            except:
                                pass

                        cmd = [
                            python_exe, "-u", str(ROOT / "scripts" / "step00_ingest_json_to_clean_sentences.py"),
                            "--domain", domain,
                            "--data-root", str(scan_path),
                            "--output", str(target_output_file)
                        ]
                        if run_command_with_progress(cmd, desc="æ­£åœ¨æ¸…æ´—æ•°æ®..."):
                            st.balloons()
                            time.sleep(1)
                            st.rerun()

            with col2:
                st.subheader("2. ç»“æœé¢„è§ˆ")
                if paths['clean'].exists():
                    try:
                        df = pd.read_parquet(paths['clean'])
                        st.metric("æ¸…æ´—åè¯­æ–™", f"{len(df):,}", delta="Ready")
                        st.dataframe(df.head(10), height=300, hide_index=True, use_container_width=True)
                    except Exception as e:
                        st.error(f"è¯»å–å¤±è´¥: {e}")
                else:
                    st.info("æš‚æ— ç»“æœï¼Œè¯·å…ˆè¿è¡Œæ¸…æ´—ä»»åŠ¡ã€‚")
# -----------------------------------------------------------------------------
# 1ï¸âƒ£ è¦†ç›–ç‡å®éªŒå®¤ (ä¿®å¤ç‰ˆï¼šç›´è¿ Worker è·å–è¿›åº¦)
# -----------------------------------------------------------------------------
elif page == "1ï¸âƒ£ è¦†ç›–ç‡å®éªŒå®¤":
    st.title("ğŸ§ª Step 01: è¦†ç›–ç‡ä¼˜åŒ–")

    if not paths['clean'].exists():
        st.error(f"âš ï¸ æ‰¾ä¸åˆ°æ•°æ®ï¼š`{paths['clean']}`\nè¯·å…ˆè¿”å› Step 00 æ‰§è¡Œæ¸…æ´—ã€‚")
        st.stop()

    if 'coverage_data' not in st.session_state:
        st.session_state.coverage_data = None

    with st.container(border=True):
        col1, col2 = st.columns([1, 1])

        # --- å·¦ä¾§ï¼šç”Ÿäº§ (Tagging) ---
        with col1:
            st.subheader("1. è§„åˆ™åŒ¹é… (Tagging)")
            st.info("æ‰§è¡Œæ­£åˆ™è„šæœ¬ï¼Œç”Ÿæˆ Aspect æ•°æ®ã€‚")

            if paths['config'].exists():
                st.caption(f"âœ… è§„åˆ™æ–‡ä»¶: `{paths['config'].name}`")

                if st.button("â–¶ï¸ è¿è¡Œè§„åˆ™åŒ¹é…", type="primary", use_container_width=True):
                    # [å…³é”®ä¿®æ”¹] ç›´æ¥è°ƒç”¨ worker è„šæœ¬ï¼Œè·³è¿‡ runnerï¼Œä»¥ä¾¿è·å–å®æ—¶ stdout
                    worker_script = ROOT / "scripts" / "tag_aspects.py"
                    output_dir = paths['aspect'].parent

                    cmd = [
                        python_exe, "-u", str(worker_script),
                        "--input", str(paths['clean']),
                        "--config", str(paths['config']),
                        "--output-dir", str(output_dir),
                        # é™ä½æ‰¹æ¬¡å¤§å°ä»¥è·å¾—æ›´é¢‘ç¹çš„è¿›åº¦æ›´æ–°
                        "--batch-size", "50000"
                    ]

                    if run_command_with_progress(cmd, desc="æ­£åˆ™åŒ¹é…è®¡ç®—ä¸­..."):
                        st.success("åŒ¹é…å®Œæˆï¼è¯·ç‚¹å‡»å³ä¾§æŒ‰é’®è¿›è¡Œåˆ†æã€‚")
                        st.session_state.coverage_data = None
                        time.sleep(1)
                        st.rerun()
            else:
                st.error("âŒ ç¼ºå¤±é…ç½®æ–‡ä»¶")
                st.markdown(f"è¯·åœ¨ä»£ç ä»“åº“åˆ›å»º:\n`{paths['config']}`")

        with col2:
            st.subheader("2. æ•ˆæœåˆ†æ (Analysis)")
            st.info("è®¡ç®—è¦†ç›–ç‡å¹¶æŒ–æ˜é—æ¼è¯ã€‚")

            if paths['aspect'].exists():
                mtime = time.ctime(os.path.getmtime(paths['aspect']))
                st.caption(f"âœ… æ•°æ®å·²å°±ç»ª (æ›´æ–°äº: {mtime})")

                if st.button("ğŸ“Š å¼€å§‹åˆ†æè¦†ç›–ç‡", use_container_width=True):
                    with st.spinner("æ­£åœ¨åˆ†ææ•°æ®..."):
                        cov, sugg, df_un = analyze_coverage(paths['clean'], paths['aspect'])
                        st.session_state.coverage_data = {
                            "coverage": cov, "suggestions": sugg, "uncovered_df": df_un
                        }
            else:
                st.warning("è¯·å…ˆè¿è¡Œå·¦ä¾§çš„è§„åˆ™åŒ¹é…ã€‚")

    # ç»“æœå±•ç¤ºåŒº
    data = st.session_state.coverage_data
    if data:
        st.divider()
        m1, m2, m3 = st.columns(3)
        cov = data["coverage"]
        m1.metric("è¦†ç›–ç‡", f"{cov:.1%}", delta_color="normal" if cov > 0.5 else "inverse")
        m2.metric("æœªåŒ¹é…", f"{len(data['uncovered_df']):,}")
        m3.metric("æ€»é‡", f"{len(pd.read_parquet(paths['clean'])):,}")

        if data["suggestions"]:
            with st.container(border=True):
                st.subheader("ğŸ§  æ™ºèƒ½å»ºè®®")
                st.caption("ä»¥ä¸‹è¯æ±‡é¢‘ç¹å‡ºç°ä½†æœªè¢«è¦†ç›–ï¼š")
                tags_html = "<div style='display: flex; flex-wrap: wrap; gap: 6px;'>"
                for word, count in data["suggestions"][:20]:
                    tags_html += f"<span style='background:#eff6ff;padding:4px 10px;border-radius:12px;font-size:0.9em;border:1px solid #bfdbfe;color:#1e40af'><b>{word}</b> <small style='opacity:0.7'>({count})</small></span>"
                tags_html += "</div>"
                st.markdown(tags_html, unsafe_allow_html=True)

        st.divider()
        # --- AI ä¼˜åŒ–åŒºåŸŸ (ç®€æ´ç‰ˆï¼Œæ—  L1 å¼€å…³) ---
        st.subheader("ğŸ§  AI è§„åˆ™è¿›åŒ–")

        c_edit, c_view = st.columns([1, 1])
        with c_edit:
            # çŠ¶æ€ç®¡ç†
            if "yaml_content" not in st.session_state:
                if paths['config'].exists():
                    st.session_state.yaml_content = paths['config'].read_text(encoding='utf-8')
                else:
                    st.session_state.yaml_content = ""

            if "pending_yaml" not in st.session_state:
                st.session_state.pending_yaml = None

            # æŒ‰é’®åŒº
            b1, b2 = st.columns(2)
            with b1:
                # é»˜è®¤ä¸¥æ ¼æ¨¡å¼ï¼šåªå¡«è¯ï¼Œä¸åŠ  L1
                if st.button("ğŸ¤– 1. AI æ™ºèƒ½åˆ†æ", use_container_width=True):
                    # [ä¿®å¤] ç»Ÿä¸€ä½¿ç”¨å…¨ç§° 'suggestions'ï¼Œå¹¶ç”¨ .get() é˜²å¾¡
                    if not data.get("suggestions"):
                        st.warning("æ— æ–°è¯")
                    else:
                        with st.spinner("AI æ€è€ƒä¸­..."):
                            w_list = [x[0] for x in data["suggestions"]]
                            cmd = [python_exe, str(ROOT / "scripts" / "optimize_rules.py"),
                                   "--yaml-path", str(paths['config']),
                                   "--suggestions", json.dumps(w_list),
                                   "--domain", domain]

                            # æ³¨å…¥ç¯å¢ƒ
                            env = os.environ.copy()
                            env["PYTHONIOENCODING"] = "utf-8"

                            res = subprocess.run(cmd, capture_output=True, text=True, encoding='utf-8', env=env)

                            if "<<<YAML_START>>>" in res.stdout:
                                new_y = res.stdout.split("<<<YAML_START>>>")[1].split("<<<YAML_END>>>")[0].strip()
                                st.session_state.pending_yaml = new_y
                                st.toast("åˆ†æå®Œæˆï¼")
                            else:
                                st.error("AIè°ƒç”¨å¤±è´¥ï¼Œè¯·æ£€æŸ¥API Keyæˆ–ç½‘ç»œ")
                                st.code(res.stdout + "\n" + res.stderr)

            with b2:
                if st.session_state.pending_yaml:
                    if st.button("âœ… 2. ç¡®è®¤å¹¶åº”ç”¨", type="primary", use_container_width=True):
                        st.session_state.yaml_content = st.session_state.pending_yaml
                        paths['config'].write_text(st.session_state.pending_yaml, encoding='utf-8')
                        st.session_state.pending_yaml = None
                        st.success("å·²ä¿å­˜ï¼è¯·é‡æ–°è¿è¡ŒåŒ¹é…ã€‚")
                        time.sleep(1)
                        st.rerun()

            # ç¼–è¾‘å™¨ / å¯¹æ¯”è§†å›¾
            if st.session_state.pending_yaml:
                st.info("ğŸ‘‡ å˜æ›´é¢„è§ˆ (å·¦ï¼šåŸç‰ˆ | å³ï¼šæ–°ç‰ˆ)")

                # è®¡ç®—å·®å¼‚ç»Ÿè®¡
                old_lines = st.session_state.yaml_content.splitlines()
                new_lines = st.session_state.pending_yaml.splitlines()
                diff = difflib.unified_diff(old_lines, new_lines, lineterm="")
                added_count = sum(1 for line in diff if line.startswith('+') and not line.startswith('+++'))
                st.caption(f"âœ¨ AI å»ºè®®æ–°å¢çº¦ **{added_count}** è¡Œé…ç½® (ä¸»è¦æ˜¯æ–° Terms)")

                d1, d2 = st.columns(2)
                d1.code(st.session_state.yaml_content, language="yaml")
                d2.code(st.session_state.pending_yaml, language="yaml")
            else:
                txt = st.text_area("ç¼–è¾‘å™¨", value=st.session_state.yaml_content, height=400)
                if txt != st.session_state.yaml_content:
                    st.session_state.yaml_content = txt
                if st.button("ğŸ’¾ æ‰‹åŠ¨ä¿å­˜é…ç½®"):
                    paths['config'].write_text(txt, encoding='utf-8')
                    st.success("å·²ä¿å­˜")

        with c_view:
            st.write("**ğŸ” æœªè¦†ç›–æ ·æœ¬**")
            st.dataframe(data['uncovered_df'].head(50), height=350, hide_index=True, use_container_width=True)

# -----------------------------------------------------------------------------
# 2ï¸âƒ£ è®­ç»ƒä¸æ¨ç† (åˆ†æ­¥ç‹¬ç«‹ç‰ˆ - ä¿®æ­£å‚æ•°æ‹¼å†™)
# -----------------------------------------------------------------------------
elif page == "2ï¸âƒ£ è®­ç»ƒä¸æ¨ç†":
    st.title("âš™ï¸ Step 02-05: ç”Ÿäº§æµæ°´çº¿ (åˆ†æ­¥æ‰§è¡Œ)")
    script_path = str(ROOT / "scripts" / "route_b_sentiment" / "pipeline.py")


    # å®šä¹‰æ£€æŸ¥ç‚¹è·¯å¾„ (ç”¨äºçŠ¶æ€æ˜¾ç¤ºçš„è¾…åŠ©å‡½æ•°)
    def check_status(step_name):
        run_dir = OUTPUTS_DIR / domain / "runs" / run_id
        if step_name == "02":
            f = run_dir / "step02_pseudo" / "train_pseudolabel.parquet"
            if f.exists(): return f"âœ… å·²å®Œæˆ (å¤§å°: {f.stat().st_size / 1024 / 1024:.2f} MB)"
        elif step_name == "03":
            # æ£€æŸ¥æ˜¯å¦æœ‰ Checkpoint å­˜æ¡£
            ckpt_dir = run_dir / "step03_model" / "ckpt"
            if ckpt_dir.exists() and any(p.name.startswith("checkpoint-") for p in ckpt_dir.iterdir()):
                return "ğŸ”„ è®­ç»ƒä¸­ (æœ‰å­˜æ¡£)"
            # æ£€æŸ¥æ˜¯å¦æœ‰æœ€ç»ˆæ¨¡å‹
            config = run_dir / "step03_model" / "config.json"
            if config.exists(): return "âœ… å·²å®Œæˆ (æ¨¡å‹å·²ä¿å­˜)"
        return "â¬œ æœªå¼€å§‹"


    # --- é¡¶éƒ¨ï¼šå…¨å±€è®¾ç½® ---
    with st.container(border=True):
        st.subheader("å…¨å±€è®¾ç½®")
        c1, c2 = st.columns(2)
        with c1:
            st.text_input("å½“å‰ä»»åŠ¡ ID", value=run_id, disabled=True)
        with c2:
            st.info(f"ğŸ“‚ æ•°æ®å°†å­˜å‚¨åœ¨: `outputs/{domain}/runs/{run_id}`")

    # --- æ ¸å¿ƒï¼šåˆ†æ­¥ Tab ---
    tab2, tab3, tab4 = st.tabs([
        "ğŸ§  Step 02: ä¼ªæ ‡ç­¾ (API)",
        "ğŸ”¥ Step 03: è®­ç»ƒ (GPU)",
        "ğŸ” Step 04: éªŒè¯ (æ¨ç†)"
    ])

    # ==================== Step 02: Teacher (DeepSeek) ====================
    with tab2:
        st.subheader("Step 02: ç”Ÿæˆä¼ªæ ‡ç­¾ (Teacher)")
        st.caption("æ­¤æ­¥éª¤è°ƒç”¨ DeepSeek/OpenAI æ¥å£ï¼Œ**ä¸æ¶ˆè€—æ˜¾å¡**ï¼Œä¸ä¼šå¯¼è‡´è¿‡çƒ­ã€‚")
        st.caption(f"å½“å‰çŠ¶æ€: {check_status('02')}")

        c1, c2, c3 = st.columns(3)
        with c1:
            sample_size = st.number_input(
                "ğŸ¯ é‡‡æ ·æ•°é‡ (Sample Size)",
                min_value=10, max_value=10000, value=500, step=100,
                help="å‘ API å‘é€å¤šå°‘æ¡æ•°æ®ã€‚æµ‹è¯•å»ºè®® 100ï¼Œç”Ÿäº§å»ºè®® 2000+"
            )
        with c2:
            batch_size_api = st.number_input("API æ‰¹æ¬¡ (Batch Size)", value=10, help="æ¯æ‰¹è¯·æ±‚å¤šå°‘æ¡")

        with c3:
            # --- æˆæœ¬ä¼°ç®—å™¨ ---
            est_cost = (sample_size * 150) / 1000 * 0.00015  # å‡è®¾ $0.15 / 1M tokens
            st.metric("é¢„è®¡ Token", f"~{sample_size * 150:,}")
            st.caption(f"é¢„è®¡è´¹ç”¨: < ${est_cost:.4f}")

        st.divider()

        if st.button("ğŸš€ è¿è¡Œ Step 02 (ç”Ÿæˆæ•°æ®)", type="primary"):
            cmd = [
                python_exe, "-u", script_path,
                "--domain", domain, "--run-id", run_id,  # <--- ä¿®æ­£ï¼šä½¿ç”¨ä¸­åˆ’çº¿ --run-id
                "--input-aspect-sentences", str(paths['aspect']),
                "--steps", "02",
                "--step02-max-rows", "0"
            ]
            # æ³¨å…¥ç¯å¢ƒå˜é‡
            os.environ["ABSA_SAMPLE_SIZE"] = str(sample_size)

            run_command_with_progress(cmd, desc="æ­£åœ¨å‘¼å« DeepSeek è€å¸ˆ...")

    # ==================== Step 03: Student (Training) ====================
    with tab3:
        st.subheader("Step 03: æ¨¡å‹è®­ç»ƒ (Student)")
        st.caption("âš ï¸ **é«˜è´Ÿè½½é¢„è­¦**ï¼šæ­¤æ­¥éª¤ä¼šæ»¡è½½æ˜¾å¡ã€‚è¯·ç¡®ä¿ Step 02 å·²å®Œæˆã€‚")

        # --- æ£€æµ‹ç»­ä¼ çŠ¶æ€ ---
        ckpt_dir_path = OUTPUTS_DIR / domain / "runs" / run_id / "step03_model" / "ckpt"
        last_ckpt_info = None

        if ckpt_dir_path.exists():
            try:
                # å¯»æ‰¾ checkpoint-XXX æ–‡ä»¶å¤¹
                ckpts = [p for p in ckpt_dir_path.iterdir() if p.is_dir() and p.name.startswith("checkpoint-")]
                if ckpts:
                    # æ‰¾æ•°å­—æœ€å¤§çš„ (æœ€æ–°)
                    latest = max(ckpts, key=lambda p: int(p.name.split("-")[-1]))
                    step_num = latest.name.split("-")[-1]

                    # æ‰¾ timestamp
                    state_file = latest / "trainer_state.json"
                    ts = state_file.stat().st_mtime if state_file.exists() else latest.stat().st_mtime
                    time_str = datetime.datetime.fromtimestamp(ts).strftime("%Y-%m-%d %H:%M:%S")

                    last_ckpt_info = {
                        "step": step_num,
                        "time": time_str,
                        "path": str(latest)
                    }
            except Exception as e:
                print(f"Ckpt check error: {e}")

        # --- UI å¸ƒå±€ ---
        c_settings, c_actions = st.columns([1, 1])

        with c_settings:
            st.markdown("#### 1. å‚æ•°è®¾ç½®")
            # æ¨¡å‹é€‰æ‹©
            model_map = {
                "hfl/chinese-macbert-base": "ğŸ† æ¨è: MacBERT Base",
                "bert-base-chinese": "ğŸ§Š è½»é‡: BERT Base (é˜²è¿‡çƒ­)",
            }
            selected_base_model = st.selectbox("åŸºåº§æ¨¡å‹", options=list(model_map.keys()),
                                               format_func=lambda x: model_map[x])

            # ç¡¬ä»¶å‚æ•°
            with st.expander("ğŸ”¥ ç¡¬ä»¶å‚æ•° (é˜²è¿‡çƒ­è®¾ç½®)", expanded=True):
                batch_size = st.select_slider("Batch Size", options=[1, 2, 4, 8, 16], value=4)
                grad_accum = st.select_slider("Grad Accum", options=[1, 2, 4, 8, 16], value=4)
                epochs = st.number_input("Epochs", value=3, min_value=1)
                st.caption(f"ç­‰æ•ˆ Batch Size = {batch_size * grad_accum}")

        with c_actions:
            st.markdown("#### 2. æ‰§è¡Œæ“ä½œ")

            # --- åœºæ™¯ A: å­˜åœ¨æ—§å­˜æ¡£ ---
            if last_ckpt_info:
                st.success(f"æ£€æµ‹åˆ°å­˜æ¡£: Step {last_ckpt_info['step']}")
                st.caption(f"å­˜æ¡£æ—¶é—´: {last_ckpt_info['time']}")

                if st.button("â–¶ï¸ ç»§ç»­è®­ç»ƒ (Resume)", type="primary", use_container_width=True):
                    st.info("æ­£åœ¨æ¢å¤... (å‚æ•°å°†è‡ªåŠ¨æ²¿ç”¨ä¸Šæ¬¡è®­ç»ƒçš„é…ç½®)")
                    cmd = [
                        python_exe, "-u", script_path,
                        "--domain", domain, "--run-id", run_id,  # <--- ä¿®æ­£ï¼šä½¿ç”¨ä¸­åˆ’çº¿ --run-id
                        "--input-aspect-sentences", str(paths['aspect']),
                        "--steps", "03",
                        "--base-model", selected_base_model,
                        "--num-train-epochs", str(epochs),
                        "--batch-size", str(batch_size),
                        "--grad-accum", str(grad_accum),
                        "--resume"
                    ]
                    run_command_with_progress(cmd, desc=f"æ­£åœ¨ä» Step {last_ckpt_info['step']} æ¢å¤...")

                if st.button("ğŸ—‘ï¸ æ”¾å¼ƒæ—§è¿›åº¦ï¼Œé‡æ–°å¼€å§‹", type="secondary", use_container_width=True):
                    import shutil

                    try:
                        shutil.rmtree(ckpt_dir_path)
                        st.toast("å·²åˆ é™¤æ—§å­˜æ¡£ï¼Œè¯·ç‚¹å‡»ä¸‹æ–¹â€˜å¼€å§‹è®­ç»ƒâ€™")
                        time.sleep(1)
                        st.rerun()
                    except Exception as e:
                        st.error(f"åˆ é™¤å¤±è´¥: {e}")

            # --- åœºæ™¯ B: æ— å­˜æ¡£ (æˆ–å·²åˆ é™¤) ---
            else:
                if st.button("ğŸ”¥ å¼€å§‹æ–°è®­ç»ƒ (Start)", type="primary", use_container_width=True):
                    if "âœ…" not in check_status('02'):
                        st.error("è¯·å…ˆåœ¨ Tab 1 å®Œæˆ Step 02ï¼")
                    else:
                        cmd = [
                            python_exe, "-u", script_path,
                            "--domain", domain, "--run-id", run_id,  # <--- ä¿®æ­£ï¼šä½¿ç”¨ä¸­åˆ’çº¿ --run-id
                            "--input-aspect-sentences", str(paths['aspect']),
                            "--steps", "03",
                            "--base-model", selected_base_model,
                            "--num-train-epochs", str(epochs),
                            "--batch-size", str(batch_size),
                            "--grad-accum", str(grad_accum)
                        ]
                        run_command_with_progress(cmd, desc="æ­£åœ¨å¼€å§‹æ–°è®­ç»ƒ...")

    # ==================== Step 04: Inference ====================
    with tab4:
        st.subheader("Step 04 & 05: æ¨ç†ä¸æŠ¥è¡¨")
        st.caption("ä½¿ç”¨è®­ç»ƒå¥½çš„æ¨¡å‹è¿›è¡Œå…¨é‡é¢„æµ‹ã€‚")

        default_model_path = ""
        potential_model = OUTPUTS_DIR / domain / "runs" / run_id / "step03_model"
        if potential_model.exists():
            default_model_path = str(potential_model)

        # 1. æ¨¡å‹è·¯å¾„
        model_path_input = st.text_input("æ¨¡å‹è·¯å¾„", value=default_model_path)

        # 2. [æ–°å¢] æ€§èƒ½ä¸æ•£çƒ­è®¾ç½®
        with st.expander("â„ï¸ æ€§èƒ½ä¸æ•£çƒ­è®¾ç½® (Performance & Cooling)", expanded=True):
            c_batch, c_cool = st.columns(2)
            with c_batch:
                infer_bs = st.select_slider(
                    "æ¨ç† Batch Size",
                    options=[4, 8, 16, 32, 64, 128],
                    value=8,
                    help="è¶Šå°è¶Šç¨³å®šï¼Œè¶Šå¤§è¶Šå¿«ï¼ˆä½†æ˜¾å­˜å‘çƒ­å¤§ï¼‰ã€‚ç¬”è®°æœ¬å»ºè®® 8-16ã€‚"
                )
            with c_cool:
                enable_cool = st.checkbox(
                    "ğŸ§Š å¼€å¯â€œæ•£çƒ­å–˜æ¯â€æ¨¡å¼",
                    value=True,
                    help="æ¯æ‰¹æ¬¡è®¡ç®—åæš‚åœ 0.5 ç§’ï¼Œé˜²æ­¢æ˜¾å¡é•¿æœŸæ»¡è½½å¯¼è‡´è¿‡çƒ­å…³æœºã€‚"
                )
                cool_time = 0.5 if enable_cool else 0.0
                if enable_cool:
                    st.caption(f"âœ… å·²å¯ç”¨: æ¯æ¬¡è®¡ç®—æ­‡ {cool_time}s")

        st.divider()

        c_run, c_resume = st.columns([1, 1])

        # å…¬å…±å‚æ•°æ„é€ 
        base_cmd = [
            python_exe, "-u", script_path,
            "--domain", domain, "--run-id", run_id,
            "--input-aspect-sentences", str(paths['aspect']),
            "--steps", "04,05,web",
            "--reuse-model", model_path_input,
            # [æ–°å¢] æ³¨å…¥ UI å‚æ•°
            "--step04-batch-size", str(infer_bs),
            "--step04-cool-down-time", str(cool_time)
        ]

        with c_run:
            if st.button("âš¡ é‡æ–°æ¨ç† (æ¸…é™¤æ—§æ•°æ®)", type="primary", use_container_width=True):
                if not model_path_input:
                    st.error("æœªæ‰¾åˆ°æ¨¡å‹è·¯å¾„")
                else:
                    run_command_with_progress(base_cmd, desc="æ­£åœ¨é‡æ–°æ¨ç†...")

        with c_resume:
            if st.button("â–¶ï¸ ç»§ç»­æ¨ç† (æ–­ç‚¹ç»­ä¼ )", use_container_width=True):
                if not model_path_input:
                    st.error("æœªæ‰¾åˆ°æ¨¡å‹è·¯å¾„")
                else:
                    # è¿½åŠ  resume
                    resume_cmd = base_cmd + ["--resume"]
                    run_command_with_progress(resume_cmd, desc="æ­£åœ¨æ¢å¤æ¨ç†...")

# -----------------------------------------------------------------------------
# 3ï¸âƒ£ æ•°æ®çœ‹æ¿ (DBç‰ˆ - åŒ…å«æ­£è´Ÿé¢æ„æˆé¥¼å›¾)
# -----------------------------------------------------------------------------
elif page == "3ï¸âƒ£ æ•°æ®çœ‹æ¿ (DBç‰ˆ)":
    st.title("ğŸ“ˆ ç»“æœæ´å¯Ÿ (Database Driven)")

    db_path = paths['db']

    # æ™ºèƒ½è·¯å¾„è¯†åˆ«
    base_run_dir = OUTPUTS_DIR / domain / "runs" / run_id / "step04_pred"
    if (base_run_dir / "asc_pred_ds").exists():
        pred_dir = base_run_dir / "asc_pred_ds"
    else:
        pred_dir = base_run_dir

    # --- 1. æ•°æ®åº“åŒæ­¥åŒº ---
    with st.expander("ğŸ”„ æ•°æ®åŒæ­¥ (Sync DB)", expanded=False):
        col_db1, col_db2 = st.columns([2, 1])
        with col_db1:
            st.info(f"æ•°æ®åº“è·¯å¾„: `{db_path}`")
        with col_db2:
            if st.button("ğŸš€ èšåˆæœ€æ–°ç»“æœå…¥åº“", use_container_width=True, type="primary"):
                if not pred_dir.exists():
                    st.error(f"âŒ æ‰¾ä¸åˆ°æ¨ç†ç»“æœç›®å½•: {pred_dir}")
                else:
                    cmd = [
                        python_exe, "-u", str(ROOT / "scripts" / "tools" / "aggregate_to_db.py"),
                        "--pred-ds", str(pred_dir),
                        "--db-path", str(db_path)
                    ]
                    if run_command_with_progress(cmd, desc="æ­£åœ¨èšåˆ Parquet åˆ° SQLite..."):
                        st.success("âœ… å…¥åº“å®Œæˆï¼")
                        time.sleep(1)
                        st.rerun()

    # --- 2. åŠ¨æ€çœ‹æ¿ ---
    if db_path.exists():
        try:
            conn = sqlite3.connect(str(db_path))

            # --- ç­›é€‰å™¨ ---
            st.subheader("ğŸ” ç­›é€‰æ¡ä»¶")
            f_col1, f_col2 = st.columns(2)

            # è·å–å“ç‰Œåˆ—è¡¨
            try:
                brands = pd.read_sql(
                    "SELECT DISTINCT brand FROM daily_sentiment_stats WHERE brand IS NOT NULL AND brand != '' ORDER BY brand",
                    conn)['brand'].tolist()
            except:
                brands = []

            if not brands:
                st.warning("âš ï¸ æ•°æ®åº“ä¸­æš‚æ— æœ‰æ•ˆå“ç‰Œæ•°æ®ï¼Œè¯·å…ˆç‚¹å‡»ä¸Šæ–¹â€œèšåˆâ€æŒ‰é’®æˆ–æ£€æŸ¥ Step 00 æ•°æ®æ¸…æ´—ã€‚")
            else:
                with f_col1:
                    sel_brands = st.multiselect("é€‰æ‹©å“ç‰Œ (Brand)", brands, default=brands[:5])

                # çº§è”è·å–å‹å·
                models = []
                if sel_brands:
                    ph = ",".join([f"'{b}'" for b in sel_brands])
                    models = pd.read_sql(
                        f"SELECT DISTINCT model FROM daily_sentiment_stats WHERE brand IN ({ph}) AND model IS NOT NULL ORDER BY model",
                        conn)['model'].tolist()
                with f_col2:
                    sel_models = st.multiselect("é€‰æ‹©å‹å· (Model)", models, default=models[:10] if models else [])

                st.divider()

                if sel_brands and sel_models:
                    # æ„é€  SQL æ¡ä»¶
                    brands_ph = ",".join([f"'{x}'" for x in sel_brands])
                    models_ph = ",".join([f"'{x}'" for x in sel_models])
                    where_clause = f"brand IN ({brands_ph}) AND model IN ({models_ph})"

                    # --- æ ¸å¿ƒæŒ‡æ ‡ KPI ---
                    kpi_sql = f"""
                        SELECT 
                            SUM(count) as total_cnt,
                            SUM(CASE WHEN sentiment='POS' THEN count ELSE 0 END) as pos_cnt,
                            SUM(CASE WHEN sentiment='NEG' THEN count ELSE 0 END) as neg_cnt
                        FROM daily_sentiment_stats
                        WHERE {where_clause}
                    """
                    df_kpi = pd.read_sql(kpi_sql, conn)
                    total = df_kpi['total_cnt'].iloc[0] or 0
                    pos_r = (df_kpi['pos_cnt'].iloc[0] or 0) / total if total > 0 else 0
                    neg_r = (df_kpi['neg_cnt'].iloc[0] or 0) / total if total > 0 else 0

                    k1, k2, k3, k4 = st.columns(4)
                    k1.metric("æ€»å£°é‡ (Volume)", f"{total:,}")
                    k2.metric("æ­£é¢ç‡ (Pos Rate)", f"{pos_r:.1%}", delta_color="normal")
                    k3.metric("è´Ÿé¢ç‡ (Neg Rate)", f"{neg_r:.1%}", delta_color="inverse")
                    k4.metric("å‡€æ¨èå€¼ (NPS Proxy)", f"{(pos_r - neg_r) * 100:.1f}")

                    st.markdown("---")

                    # === è·å–èšåˆæ•°æ®ç”¨äºç”»å›¾ ===
                    pie_sql = f"""
                        SELECT aspect, sentiment, SUM(count) as count
                        FROM daily_sentiment_stats
                        WHERE {where_clause} AND aspect IS NOT NULL AND aspect != ''
                        GROUP BY 1, 2
                    """
                    df_pie = pd.read_sql(pie_sql, conn)

                    # === ç¬¬ä¸€æ’ï¼šæ€»ä½“æƒ…æ„Ÿ + æ—­æ—¥å›¾ ===
                    st.subheader("ğŸ¥§ æƒ…æ„Ÿåˆ†å¸ƒé€è§†")
                    r1_c1, r1_c2 = st.columns([1, 1])

                    # 1. æ€»ä½“æƒ…æ„Ÿé¥¼å›¾
                    with r1_c1:
                        st.markdown("##### ğŸŸ¢ æ€»ä½“æƒ…æ„Ÿå æ¯” (Global Sentiment)")
                        if not df_pie.empty:
                            df_global_pie = df_pie.groupby("sentiment")["count"].sum().reset_index()
                            fig_g_pie = px.pie(df_global_pie, values='count', names='sentiment',
                                               color='sentiment',
                                               color_discrete_map={'POS': '#10b981', 'NEG': '#ef4444',
                                                                   'NEU': '#9ca3af'},
                                               hole=0.4)
                            fig_g_pie.update_traces(textinfo='percent+label')
                            st.plotly_chart(fig_g_pie, use_container_width=True)
                        else:
                            st.caption("æš‚æ— æ•°æ®")

                    # 2. æ—­æ—¥å›¾
                    with r1_c2:
                        st.markdown("##### â˜€ï¸ å„æ–¹é¢æ­£è´Ÿé¢åˆ†å¸ƒ (Aspect Sunburst)")
                        if not df_pie.empty:
                            top_aspects = df_pie.groupby("aspect")["count"].sum().nlargest(15).index.tolist()
                            df_pie['aspect_clean'] = df_pie['aspect'].apply(
                                lambda x: x if x in top_aspects else 'Other')

                            fig_sun = px.sunburst(df_pie, path=['aspect_clean', 'sentiment'], values='count',
                                                  color='sentiment',
                                                  color_discrete_map={'POS': '#10b981', 'NEG': '#ef4444',
                                                                      'NEU': '#9ca3af', '(?)': '#ddd'})
                            st.plotly_chart(fig_sun, use_container_width=True)
                        else:
                            st.caption("æš‚æ— æ•°æ®")

                    # === [NEW] ç¬¬äºŒæ’ï¼šæ­£è´Ÿé¢è¯„ä»·çš„å…·ä½“æ„æˆ ===
                    st.divider()
                    st.subheader("ğŸ­ æ­£/è´Ÿé¢è¯„ä»·çš„å…·ä½“æ„æˆ")
                    st.caption("ä¸‹å›¾åˆ†åˆ«å±•ç¤ºï¼šåœ¨æ‰€æœ‰**å¥½è¯„**ä¸­å„æ–¹é¢çš„å æ¯”ï¼Œä»¥åŠåœ¨æ‰€æœ‰**å·®è¯„**ä¸­å„æ–¹é¢çš„å æ¯”ã€‚")

                    pn_c1, pn_c2 = st.columns(2)


                    # è¾…åŠ©å‡½æ•°ï¼šåªå– Top 10ï¼Œå…¶ä»–çš„åˆå¹¶ä¸º Otherï¼Œé˜²æ­¢é¥¼å›¾å¤ªç¢
                    def get_top_aspects_df(source_df, sentiment_label, top_n=12):
                        subset = source_df[source_df['sentiment'] == sentiment_label].copy()
                        if subset.empty: return subset

                        # æŒ‰æ•°é‡æ’åº
                        subset = subset.sort_values('count', ascending=False)

                        # å–å‰ N ä¸ª
                        top_items = subset.head(top_n)

                        # è®¡ç®— "Other"
                        other_count = subset.iloc[top_n:]['count'].sum()
                        if other_count > 0:
                            # æ„é€ ä¸€è¡Œ Other æ•°æ®
                            other_row = pd.DataFrame(
                                {'aspect': ['Other'], 'sentiment': [sentiment_label], 'count': [other_count]})
                            return pd.concat([top_items, other_row], ignore_index=True)
                        return top_items


                    # 3. æ­£é¢æ„æˆé¥¼å›¾
                    with pn_c1:
                        st.markdown("##### ğŸ‘ æ­£é¢è¯„ä»·éƒ½åœ¨å¤¸ä»€ä¹ˆ (Positive Mix)")
                        df_pos_pie = get_top_aspects_df(df_pie, 'POS')
                        if not df_pos_pie.empty:
                            # ä½¿ç”¨ Pastel è‰²ç³»ï¼Œçœ‹èµ·æ¥æ¯”è¾ƒæŸ”å’Œ
                            fig_p = px.pie(df_pos_pie, values='count', names='aspect', hole=0.3,
                                           color_discrete_sequence=px.colors.qualitative.Pastel)
                            fig_p.update_traces(textposition='inside', textinfo='percent+label')
                            st.plotly_chart(fig_p, use_container_width=True)
                        else:
                            st.info("æ— æ­£é¢è¯„ä»·æ•°æ®")

                    # 4. è´Ÿé¢æ„æˆé¥¼å›¾
                    with pn_c2:
                        st.markdown("##### ğŸ‘ è´Ÿé¢è¯„ä»·éƒ½åœ¨éª‚ä»€ä¹ˆ (Negative Mix)")
                        df_neg_pie = get_top_aspects_df(df_pie, 'NEG')
                        if not df_neg_pie.empty:
                            # ä½¿ç”¨ Set3 è‰²ç³»ï¼Œä¸å·¦è¾¹åŒºåˆ†å¼€
                            fig_n = px.pie(df_neg_pie, values='count', names='aspect', hole=0.3,
                                           color_discrete_sequence=px.colors.qualitative.Set3)
                            fig_n.update_traces(textposition='inside', textinfo='percent+label')
                            st.plotly_chart(fig_n, use_container_width=True)
                        else:
                            st.info("æ— è´Ÿé¢è¯„ä»·æ•°æ®")

                    st.markdown("---")

                    # === ç¬¬ä¸‰æ’ï¼šå †å æ¡å½¢å›¾ ===
                    if not df_pie.empty:
                        st.markdown("##### ğŸ“Š å„æ–¹é¢æƒ…æ„Ÿæ¯”ä¾‹å¯¹æ¯” (Stacked Bar)")
                        # è®¡ç®—æ¯ä¸ª Aspect çš„æ€»é‡ï¼Œç”¨äºæ’åºï¼Œåªæ˜¾ç¤º Top 20
                        aspect_totals = df_pie.groupby('aspect')['count'].sum().sort_values(ascending=False).head(
                            20).index
                        df_bar = df_pie[df_pie['aspect'].isin(aspect_totals)]

                        fig_stack = px.bar(df_bar, x='aspect', y='count', color='sentiment',
                                           color_discrete_map={'POS': '#10b981', 'NEG': '#ef4444', 'NEU': '#9ca3af'},
                                           category_orders={"aspect": aspect_totals})
                        # è®¾ä¸ºç™¾åˆ†æ¯”å †å ï¼Œæ–¹ä¾¿çœ‹â€œå¥½è¯„ç‡â€å¯¹æ¯”
                        fig_stack.update_layout(barnorm='percent', xaxis_title=None, yaxis_title="Percentage")
                        st.plotly_chart(fig_stack, use_container_width=True)

                    st.markdown("---")

                    # === ç¬¬å››æ’ï¼šè¶‹åŠ¿ä¸æ’å ===
                    c1, c2 = st.columns([2, 1])

                    # 5. æ¯æ—¥è¶‹åŠ¿å›¾
                    with c1:
                        st.markdown("##### ğŸ“… å£°é‡ä¸æƒ…æ„Ÿè¶‹åŠ¿ (Daily Trend)")
                        trend_sql = f"""
                            SELECT date, sentiment, SUM(count) as count
                            FROM daily_sentiment_stats
                            WHERE {where_clause}
                            GROUP BY 1, 2
                            ORDER BY 1
                        """
                        df_trend = pd.read_sql(trend_sql, conn)
                        fig_trend = px.line(df_trend, x='date', y='count', color='sentiment',
                                            color_discrete_map={'POS': '#10b981', 'NEG': '#ef4444', 'NEU': '#9ca3af'},
                                            markers=True)
                        st.plotly_chart(fig_trend, use_container_width=True)

                    # 6. è´Ÿé¢ Aspect æ’å
                    with c2:
                        st.markdown("##### ğŸš¨ Top 10 è´Ÿé¢å…³æ³¨ç‚¹")
                        aspect_sql = f"""
                            SELECT aspect, SUM(count) as cnt
                            FROM daily_sentiment_stats
                            WHERE {where_clause} AND sentiment='NEG'
                            GROUP BY 1
                            ORDER BY 2 DESC
                            LIMIT 10
                        """
                        df_aspect = pd.read_sql(aspect_sql, conn)
                        if not df_aspect.empty:
                            fig_bar = px.bar(df_aspect, x='cnt', y='aspect', orientation='h',
                                             color_discrete_sequence=['#ef4444'])
                            fig_bar.update_layout(yaxis={'categoryorder': 'total ascending'})
                            st.plotly_chart(fig_bar, use_container_width=True)
                        else:
                            st.info("æ— è´Ÿé¢æ•°æ®")

                else:
                    st.info("ğŸ‘ˆ è¯·å…ˆåœ¨å·¦ä¾§é€‰æ‹©å“ç‰Œå’Œå‹å·ä»¥æŸ¥çœ‹æ•°æ®ã€‚")

            conn.close()
        except Exception as e:
            st.error(f"æ•°æ®åº“è¯»å–é”™è¯¯: {e}")
            import traceback

            st.code(traceback.format_exc())
    else:
        st.info("ç­‰å¾…æ•°æ®åº“åˆå§‹åŒ–...")